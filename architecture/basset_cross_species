
import os, errno
#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #suppress irrelevent warning messages
import keras;
import numpy as np
from keras.models import Sequential
from keras.layers.core import Dropout, Reshape, Dense, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import Adadelta, SGD, RMSprop;
from keras.constraints import maxnorm;
from keras.layers.advanced_activations import PReLU
from keras.layers.normalization import BatchNormalization
from keras.regularizers import l1, l2
import sklearn
from sklearn.metrics import average_precision_score, precision_recall_curve
import matplotlib.pyplot as plt
from keras.utils import to_categorical
import pandas
import time
import pydot
import graphviz
from keras.utils import plot_model
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot


print("cross-species validation")

start_time = time.time()

np.random.seed(1234) #sets random seed for consistency
seq_length = 2000 #2kb iput
num_labels = 1    #Our binary final prediction. The only label is the predicted probability that the gene is on or whatever
num_epochs = 1	  #Number of epochs to train for
##########################
init_weights_file = 'model_weights_poster.h5' #load in pre-trained weights/parameters Anna gave us here if we're using them. Elsewise, leave as None.
##########################
 

val_x_file = 'validationOneHotEncoding.dat'
val_y_file = 'validationLabel.dat'
size_file = 'fileSize.txt'

with open(size_file, 'r') as f:
    first_line = f.readline().strip()

num_val_examples = int(first_line)#315426
X_val = np.memmap(val_x_file, dtype=np.bool_, mode='r', shape=(num_val_examples, 1, 2000, 4))
Y_val = np.memmap(val_y_file, dtype=np.bool_, mode='r', shape=(num_val_examples))


#Build model based heavily on original Basset architecture
model = Sequential() #Multiple models can be made, each corresponding to a different species
model.add(Convolution2D(300,(1,19),input_shape=(1,int(seq_length), 4)))#, activity_regularizer=l1(0.00001))) #the 1 and the 4 should be switched here. Correct order would be 300,(1,19) and (1,int(seq_length), 4)))
model.add(BatchNormalization(axis=-1))	#Isn't in all versions but is good
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(1,3)))

model.add(Convolution2D(filters=200,kernel_size=(1,11)))#, activity_regularizer=l1(0.00001)))
model.add(BatchNormalization(axis=-1))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(1,4)))

model.add(Convolution2D(filters=200,kernel_size=(1,7)))#, activity_regularizer=l1(0.00001)))
model.add(BatchNormalization(axis=-1))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(1,4)))

model.add(Flatten())
model.add(Dense(1000))#,activity_regularizer=activity_l2(0.00001))#, activity_regularizer=l2(0.00001)))
model.add(BatchNormalization(axis=-1))
model.add(Activation('relu'))
model.add(Dropout(0.3))

model.add(Dense(1000))#,activity_regularizer=activity_l2(0.00001))#, activity_regularizer=l2(0.00001)))
model.add(BatchNormalization(axis=-1))
model.add(Activation('relu'))
model.add(Dropout(0.3))

model.add(Dense(num_labels)) 
model.add(Activation("sigmoid"))

adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08) #originally lr was 0.001
model.compile(loss="binary_crossentropy",optimizer=adam, metrics=['accuracy']) 

#Load weights if they exist
if init_weights_file!=None:
	print("Restoring Weights")
	model.load_weights(init_weights_file)

y_probs = model.predict_proba(X_val)							#Predicted probability that each label is positive
AU_PRC = average_precision_score(Y_val, y_probs)				#Area under PR curve taken as average of precisions for all recalls
precision, recall, _ = precision_recall_curve(Y_val, y_probs)	#Arrays for plotting precision recall curve
print('Max prob val:', np.amax(y_probs))
print('Min prob val:', np.amin(y_probs))
print('Val AUPRC:', AU_PRC)
score = model.evaluate(X_val, Y_val, verbose=0)
print('Val loss:', score[0])
print('Val accuracy:', score[1])

print("Finished after " + str(time.time()-start_time))




